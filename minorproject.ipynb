{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cytWWc0IBq-A"
      },
      "outputs": [],
      "source": [
        "This is the code to split the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YahmsF6ICv27",
        "outputId": "50be889d-d335-4fd6-e132-29d1b6898e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset split into training and validation sets for each class.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from shutil import copy2, copytree\n",
        "\n",
        "# Set the path to your training dataset directory\n",
        "training_dataset_path = \"/content/drive/MyDrive/Training\"\n",
        "\n",
        "# Set the path to the directory where you want to store the training and validation sets\n",
        "output_path = \"/content/drive/MyDrive/output\"\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "train_path = os.path.join(output_path, 'train')\n",
        "valid_path = os.path.join(output_path, 'validation')\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(valid_path, exist_ok=True)\n",
        "\n",
        "# List all subdirectories (assuming each subdirectory is a class)\n",
        "classes = os.listdir(training_dataset_path)\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(training_dataset_path, class_name)\n",
        "    train_class_path = os.path.join(train_path, class_name)\n",
        "    valid_class_path = os.path.join(valid_path, class_name)\n",
        "\n",
        "    os.makedirs(train_class_path, exist_ok=True)\n",
        "    os.makedirs(valid_class_path, exist_ok=True)\n",
        "\n",
        "    # List all files in the current class directory\n",
        "    all_files = os.listdir(class_path)\n",
        "\n",
        "    # Skip split if the number of samples is too small\n",
        "    if len(all_files) < 2:\n",
        "        print(f\"Skipping split for {class_name} due to insufficient samples.\")\n",
        "        continue\n",
        "\n",
        "    # Split the files into training and validation sets\n",
        "    train_files, valid_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Copy training set files to the 'train' subdirectory for the specific class\n",
        "    for file in train_files:\n",
        "        src = os.path.join(class_path, file)\n",
        "        dst = os.path.join(train_class_path, file)\n",
        "        if os.path.isdir(src):\n",
        "            copytree(src, dst)\n",
        "        else:\n",
        "            copy2(src, dst)\n",
        "\n",
        "    # Copy validation set files to the 'validation' subdirectory for the specific class\n",
        "    for file in valid_files:\n",
        "        src = os.path.join(class_path, file)\n",
        "        dst = os.path.join(valid_class_path, file)\n",
        "        if os.path.isdir(src):\n",
        "            copytree(src, dst)\n",
        "        else:\n",
        "            copy2(src, dst)\n",
        "\n",
        "print(\"Training dataset split into training and validation sets for each class.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0EmEfLHDMWT"
      },
      "source": [
        "This is the code after data splitting, code for the no. of splitted images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzHS0uSZDWjn",
        "outputId": "4d07e0b0-e8cd-4a05-aae3-8cee35c2be15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image type: glioma\n",
            "  Training images: 1056\n",
            "  Validation images: 265\n",
            "  Total images: 1321\n",
            "\n",
            "Image type: meningioma\n",
            "  Training images: 1071\n",
            "  Validation images: 268\n",
            "  Total images: 1339\n",
            "\n",
            "Image type: notumor\n",
            "  Training images: 1276\n",
            "  Validation images: 319\n",
            "  Total images: 1595\n",
            "\n",
            "Image type: pituitary\n",
            "  Training images: 1165\n",
            "  Validation images: 292\n",
            "  Total images: 1457\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/output\"\n",
        "image_types = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]  # Replace with your actual image types\n",
        "\n",
        "for image_type in image_types:\n",
        "    train_folder = os.path.join(base_path, 'train', image_type)\n",
        "    val_folder = os.path.join(base_path, 'validation', image_type)\n",
        "\n",
        "    train_count = len(os.listdir(train_folder))\n",
        "    val_count = len(os.listdir(val_folder))\n",
        "\n",
        "    print(f\"Image type: {image_type}\")\n",
        "    print(f\"  Training images: {train_count}\")\n",
        "    print(f\"  Validation images: {val_count}\")\n",
        "    print(f\"  Total images: {train_count + val_count}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrYRFR_Dlcn"
      },
      "source": [
        "This is the code for images preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGs0EZxSDsU_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/output\"\n",
        "image_types = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "\n",
        "# Output directory for preprocessed images\n",
        "preprocessed_path = \"/content/drive/MyDrive/processed_images\"\n",
        "os.makedirs(preprocessed_path, exist_ok=True)\n",
        "\n",
        "# Function to preprocess and save images\n",
        "def preprocess_images(input_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for image_type in image_types:\n",
        "        input_type_folder = os.path.join(input_folder, image_type)\n",
        "        output_type_folder = os.path.join(output_folder, image_type)\n",
        "\n",
        "        os.makedirs(output_type_folder, exist_ok=True)\n",
        "\n",
        "        # Print the paths for debugging\n",
        "        print(f\"Input folder: {input_type_folder}\")\n",
        "        print(f\"Output folder: {output_type_folder}\")\n",
        "\n",
        "        for file_name in tqdm(os.listdir(input_type_folder), desc=f\"Processing {image_type}\"):\n",
        "            input_path = os.path.join(input_type_folder, file_name)\n",
        "            output_path = os.path.join(output_type_folder, file_name)\n",
        "\n",
        "            # Print the file names for debugging\n",
        "            print(f\"Input file: {input_path}\")\n",
        "            print(f\"Output file: {output_path}\")\n",
        "\n",
        "            # Read image\n",
        "            img = cv2.imread(input_path)\n",
        "\n",
        "            # Preprocessing steps (e.g., resizing, normalization)\n",
        "            # Example: Resize to 224x224 pixels\n",
        "            img = cv2.resize(img, (512, 512))\n",
        "\n",
        "            # Save preprocessed image\n",
        "            cv2.imwrite(output_path, img)\n",
        "\n",
        "# Preprocess training images\n",
        "preprocess_images(os.path.join(base_path, 'train'), os.path.join(preprocessed_path, 'train'))\n",
        "\n",
        "# Preprocess validation images\n",
        "preprocess_images(os.path.join(base_path, 'validation'), os.path.join(preprocessed_path, 'validation'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNjGHaXADzFI"
      },
      "outputs": [],
      "source": [
        "This is the code for create, compile and train the model.(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3belSlQD2-D",
        "outputId": "2f839b56-758e-44e3-8703-8b115b73e996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4568 images belonging to 4 classes.\n",
            "Found 1144 images belonging to 4 classes.\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 3175s 22s/step - loss: 0.9488 - accuracy: 0.7314 - val_loss: 0.3778 - val_accuracy: 0.8794\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3057s 21s/step - loss: 0.2355 - accuracy: 0.9177 - val_loss: 0.3182 - val_accuracy: 0.8925\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3058s 21s/step - loss: 0.1096 - accuracy: 0.9634 - val_loss: 0.2801 - val_accuracy: 0.9248\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3095s 22s/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.2893 - val_accuracy: 0.9309\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3045s 21s/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.3758 - val_accuracy: 0.9126\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3073s 21s/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.3674 - val_accuracy: 0.9266\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3010s 21s/step - loss: 0.0742 - accuracy: 0.9794 - val_loss: 0.3577 - val_accuracy: 0.9231\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9965 "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set your data paths\n",
        "train_data_dir = \"/content/drive/MyDrive/processed_images/train\"\n",
        "val_data_dir = \"/content/drive/MyDrive/processed_images/validation\"\n",
        "\n",
        "# Define the new input shape based on your image size\n",
        "input_shape = (512, 512, 3)\n",
        "\n",
        "# Create a simple CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(4, activation='softmax'))  # 4 classes (3 tumor types + no tumor)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Create data generators for training and validation\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model with validation accuracy monitoring\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    verbose=1  # Set verbose to 1 to see training and validation progress\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zLiCsbrEEKF"
      },
      "source": [
        "This is the code for the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lko45IcHEJLO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the 'history' object from model training\n",
        "# history = model.fit(...)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGBibRYjER3p"
      },
      "source": [
        "This is the code to save the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIfI__Q-EVGf"
      },
      "outputs": [],
      "source": [
        " # Save the trained model\n",
        " model.save(\"/content/drive/MyDrive/Brain_Tumor_Model.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}